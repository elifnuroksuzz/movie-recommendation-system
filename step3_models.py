# step3_models.py - ÃœÃ§Ã¼ncÃ¼ AdÄ±m: Model GeliÅŸtirme

import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error, mean_absolute_error
import pickle
import warnings
warnings.filterwarnings('ignore')

class CollaborativeFiltering:
    """KullanÄ±cÄ±-tabanlÄ± Collaborative Filtering"""
    
    def __init__(self, k_users=50):
        self.k_users = k_users  # En benzer k kullanÄ±cÄ±
        self.user_similarity = None
        self.user_item_matrix = None
        self.user_means = None
        
    def fit(self, user_item_matrix):
        """Modeli eÄŸit"""
        print(f"ğŸ¤ Collaborative Filtering eÄŸitiliyor... (k={self.k_users})")
        
        self.user_item_matrix = user_item_matrix
        
        # KullanÄ±cÄ± ortalamalarÄ±nÄ± hesapla (sadece 0 olmayanlar iÃ§in)
        self.user_means = {}
        for user in user_item_matrix.index:
            user_ratings = user_item_matrix.loc[user]
            non_zero_ratings = user_ratings[user_ratings > 0]
            self.user_means[user] = non_zero_ratings.mean() if len(non_zero_ratings) > 0 else 0
        
        # KullanÄ±cÄ± benzerliÄŸini hesapla (cosine similarity)
        print("   ğŸ“Š KullanÄ±cÄ± benzerlik matrisi hesaplanÄ±yor...")
        
        # Matrix'i normalize et (kullanÄ±cÄ± ortalamasÄ±nÄ± Ã§Ä±kar)
        normalized_matrix = user_item_matrix.copy()
        for user in user_item_matrix.index:
            user_mean = self.user_means[user]
            # Sadece rating verilmiÅŸ filmleri normalize et
            mask = user_item_matrix.loc[user] > 0
            normalized_matrix.loc[user, mask] = user_item_matrix.loc[user, mask] - user_mean
        
        # Cosine similarity hesapla
        self.user_similarity = cosine_similarity(normalized_matrix.fillna(0))
        
        print("âœ… Model eÄŸitimi tamamlandÄ±!")
        
    def predict(self, user_id, movie_id):
        """Tek tahmin yap"""
        if user_id not in self.user_item_matrix.index:
            return 3.0  # VarsayÄ±lan deÄŸer
        
        if movie_id not in self.user_item_matrix.columns:
            return 3.0  # VarsayÄ±lan deÄŸer
            
        # KullanÄ±cÄ±nÄ±n indeksini bul
        user_idx = list(self.user_item_matrix.index).index(user_id)
        
        # Bu kullanÄ±cÄ±ya en benzer kullanÄ±cÄ±larÄ± bul
        user_similarities = self.user_similarity[user_idx]
        
        # Kendisini hariÃ§ tut
        user_similarities[user_idx] = -1
        
        # En benzer k kullanÄ±cÄ±yÄ± seÃ§
        similar_users_idx = np.argsort(user_similarities)[-self.k_users:]
        
        weighted_sum = 0
        similarity_sum = 0
        
        for similar_user_idx in similar_users_idx:
            if user_similarities[similar_user_idx] <= 0:
                continue
                
            similar_user_id = self.user_item_matrix.index[similar_user_idx]
            similar_user_rating = self.user_item_matrix.loc[similar_user_id, movie_id]
            
            if similar_user_rating > 0:  # Bu kullanÄ±cÄ± bu filme rating vermiÅŸ
                similarity = user_similarities[similar_user_idx]
                similar_user_mean = self.user_means[similar_user_id]
                
                weighted_sum += similarity * (similar_user_rating - similar_user_mean)
                similarity_sum += similarity
        
        if similarity_sum == 0:
            return self.user_means[user_id]
        
        prediction = self.user_means[user_id] + (weighted_sum / similarity_sum)
        
        # Rating aralÄ±ÄŸÄ±nda tut (1-5)
        return max(1, min(5, prediction))
    
    def predict_batch(self, test_pairs):
        """Toplu tahmin"""
        predictions = []
        print(f"ğŸ”® {len(test_pairs)} tahmin yapÄ±lÄ±yor...")
        
        for i, (user_id, movie_id) in enumerate(test_pairs):
            pred = self.predict(user_id, movie_id)
            predictions.append(pred)
            
            if (i + 1) % 5000 == 0:
                print(f"   {i + 1}/{len(test_pairs)} tahmin tamamlandÄ±")
        
        return np.array(predictions)

class ContentBasedFiltering:
    """Ä°Ã§erik-tabanlÄ± Filtering"""
    
    def __init__(self):
        self.item_similarity = None
        self.movies_df = None
        self.user_profiles = None
        
    def fit(self, movies_df, ratings_df):
        """Modeli eÄŸit"""
        print("ğŸ¬ Content-Based Filtering eÄŸitiliyor...")
        
        self.movies_df = movies_df
        
        # Genre Ã¶zelliklerini al
        genre_features = movies_df[[col for col in movies_df.columns if col.startswith('genre_')]]
        
        # Film benzerliÄŸini hesapla
        print("   ğŸ­ Film benzerlik matrisi hesaplanÄ±yor...")
        self.item_similarity = cosine_similarity(genre_features)
        
        # KullanÄ±cÄ± profillerini oluÅŸtur (hangi tÃ¼rleri seviyor)
        print("   ğŸ‘¤ KullanÄ±cÄ± profilleri oluÅŸturuluyor...")
        self.user_profiles = {}
        
        for user_id in ratings_df['user_id'].unique():
            user_ratings = ratings_df[ratings_df['user_id'] == user_id]
            
            # Bu kullanÄ±cÄ±nÄ±n verdiÄŸi yÃ¼ksek rating'li filmler (4-5)
            liked_movies = user_ratings[user_ratings['rating'] >= 4]['movie_id'].values
            
            # Bu filmlerin genre Ã¶zelliklerini topla
            user_profile = np.zeros(len(genre_features.columns))
            
            for movie_id in liked_movies:
                if movie_id in movies_df['movie_id'].values:
                    movie_idx = movies_df[movies_df['movie_id'] == movie_id].index[0]
                    user_profile += genre_features.iloc[movie_idx].values
            
            # Normalize et
            if np.sum(user_profile) > 0:
                user_profile = user_profile / np.sum(user_profile)
            
            self.user_profiles[user_id] = user_profile
        
        print("âœ… Content-Based model eÄŸitimi tamamlandÄ±!")
    
    def predict(self, user_id, movie_id):
        """Tek tahmin yap"""
        if user_id not in self.user_profiles:
            return 3.0
            
        if movie_id not in self.movies_df['movie_id'].values:
            return 3.0
        
        # Film Ã¶zelliklerini al
        movie_idx = self.movies_df[self.movies_df['movie_id'] == movie_id].index[0]
        movie_features = self.movies_df[[col for col in self.movies_df.columns if col.startswith('genre_')]].iloc[movie_idx].values
        
        # KullanÄ±cÄ± profili ile film Ã¶zelliÄŸi arasÄ±ndaki benzerlik
        user_profile = self.user_profiles[user_id]
        
        if np.sum(user_profile) == 0 or np.sum(movie_features) == 0:
            return 3.0
        
        similarity = np.dot(user_profile, movie_features)
        
        # Similarity'yi 1-5 rating aralÄ±ÄŸÄ±na dÃ¶nÃ¼ÅŸtÃ¼r
        prediction = 1 + 4 * similarity  # 0-1 arasÄ± similarity'yi 1-5'e scale et
        
        return max(1, min(5, prediction))
    
    def predict_batch(self, test_pairs):
        """Toplu tahmin"""
        predictions = []
        print(f"ğŸ­ {len(test_pairs)} content-based tahmin yapÄ±lÄ±yor...")
        
        for user_id, movie_id in test_pairs:
            pred = self.predict(user_id, movie_id)
            predictions.append(pred)
        
        return np.array(predictions)

def evaluate_model(y_true, y_pred, model_name):
    """Model performansÄ±nÄ± deÄŸerlendir"""
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mae = mean_absolute_error(y_true, y_pred)
    
    print(f"\nğŸ“Š {model_name} PerformansÄ±:")
    print(f"   RMSE: {rmse:.4f}")
    print(f"   MAE: {mae:.4f}")
    
    return {'rmse': rmse, 'mae': mae}

def cross_validation(model, train_df, user_item_matrix, movies_df=None, k_folds=5):
    """K-fold Ã§apraz doÄŸrulama"""
    print(f"\nğŸ”„ {k_folds}-fold Ã§apraz doÄŸrulama baÅŸlÄ±yor...")
    
    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)
    
    rmse_scores = []
    mae_scores = []
    
    for fold, (train_idx, val_idx) in enumerate(kf.split(train_df)):
        print(f"   ğŸ“ Fold {fold + 1}/{k_folds}")
        
        # Bu fold iÃ§in train ve validation setlerini al
        fold_train = train_df.iloc[train_idx]
        fold_val = train_df.iloc[val_idx]
        
        # Model tÃ¼rÃ¼ne gÃ¶re eÄŸit
        if hasattr(model, 'user_similarity'):  # Collaborative Filtering
            # Bu fold iÃ§in user-item matrix oluÅŸtur
            fold_matrix = fold_train.pivot_table(
                index='user_id', columns='movie_id', values='rating', fill_value=0
            )
            model.fit(fold_matrix)
        else:  # Content-Based Filtering
            model.fit(movies_df, fold_train)
        
        # Validation seti iÃ§in tahmin yap
        val_pairs = [(row['user_id'], row['movie_id']) for _, row in fold_val.iterrows()]
        predictions = model.predict_batch(val_pairs)
        
        # PerformansÄ± deÄŸerlendir
        true_ratings = fold_val['rating'].values
        rmse = np.sqrt(mean_squared_error(true_ratings, predictions))
        mae = mean_absolute_error(true_ratings, predictions)
        
        rmse_scores.append(rmse)
        mae_scores.append(mae)
    
    print(f"\nâœ… Ã‡apraz doÄŸrulama tamamlandÄ±!")
    print(f"   Ortalama RMSE: {np.mean(rmse_scores):.4f} (Â±{np.std(rmse_scores):.4f})")
    print(f"   Ortalama MAE: {np.mean(mae_scores):.4f} (Â±{np.std(mae_scores):.4f})")
    
    return {
        'rmse_mean': np.mean(rmse_scores),
        'rmse_std': np.std(rmse_scores),
        'mae_mean': np.mean(mae_scores),
        'mae_std': np.std(mae_scores)
    }

def main():
    """Ana fonksiyon"""
    print("ğŸ¯ ÃœÃ‡ÃœNCÃœ ADIM: MODEL GELÄ°ÅTÄ°RME")
    print("="*50)
    
    # Veriyi yÃ¼kle
    print("ğŸ“¥ Veriler yÃ¼kleniyor...")
    user_item_matrix = pd.read_csv('data/processed/user_item_matrix.csv', index_col=0)
    train_df = pd.read_csv('data/processed/train_ratings.csv')
    test_df = pd.read_csv('data/processed/test_ratings.csv')
    movies_df = pd.read_csv('data/processed/movies.csv')
    
    print("âœ… Veriler yÃ¼klendi!")
    
    # 1. Collaborative Filtering
    print(f"\n{'='*50}")
    print("ğŸ¤ COLLABORATIVE FILTERING")
    print("="*50)
    
    cf_model = CollaborativeFiltering(k_users=30)
    cf_model.fit(user_item_matrix)
    
    # Ã‡apraz doÄŸrulama
    cf_cv_results = cross_validation(cf_model, train_df, user_item_matrix, k_folds=3)
    
    # Test seti deÄŸerlendirmesi
    print("\nğŸ§ª Test seti deÄŸerlendiriliyor...")
    test_pairs = [(row['user_id'], row['movie_id']) for _, row in test_df.iterrows()]
    cf_predictions = cf_model.predict_batch(test_pairs)
    cf_results = evaluate_model(test_df['rating'].values, cf_predictions, "Collaborative Filtering")
    
    # 2. Content-Based Filtering
    print(f"\n{'='*50}")
    print("ğŸ¬ CONTENT-BASED FILTERING")  
    print("="*50)
    
    cb_model = ContentBasedFiltering()
    cb_model.fit(movies_df, train_df)
    
    # Ã‡apraz doÄŸrulama
    cb_cv_results = cross_validation(cb_model, train_df, user_item_matrix, movies_df, k_folds=3)
    
    # Test seti deÄŸerlendirmesi
    cb_predictions = cb_model.predict_batch(test_pairs)
    cb_results = evaluate_model(test_df['rating'].values, cb_predictions, "Content-Based Filtering")
    
    # 3. Hibrit Model (Basit aÄŸÄ±rlÄ±klÄ± ortalama)
    print(f"\n{'='*50}")
    print("ğŸ”„ HÄ°BRÄ°T MODEL")
    print("="*50)
    
    # %70 Collaborative + %30 Content-Based
    hybrid_predictions = 0.7 * cf_predictions + 0.3 * cb_predictions
    hybrid_results = evaluate_model(test_df['rating'].values, hybrid_predictions, "Hybrid Model")
    
    # 4. SonuÃ§larÄ± karÅŸÄ±laÅŸtÄ±r
    print(f"\n{'='*50}")
    print("ğŸ“Š SONUÃ‡LAR KARÅILAÅTIRMASI")
    print("="*50)
    
    results_df = pd.DataFrame({
        'Model': ['Collaborative Filtering', 'Content-Based', 'Hybrid'],
        'RMSE': [cf_results['rmse'], cb_results['rmse'], hybrid_results['rmse']],
        'MAE': [cf_results['mae'], cb_results['mae'], hybrid_results['mae']]
    })
    
    print(results_df.round(4))
    
    # En iyi modeli belirle
    best_model_idx = results_df['RMSE'].idxmin()
    best_model = results_df.loc[best_model_idx, 'Model']
    print(f"\nğŸ† En iyi model: {best_model}")
    
    # 5. Modelleri kaydet
    print(f"\nğŸ’¾ Modeller kaydediliyor...")
    with open('models/collaborative_model.pkl', 'wb') as f:
        pickle.dump(cf_model, f)
    
    with open('models/content_based_model.pkl', 'wb') as f:
        pickle.dump(cb_model, f)
    
    # SonuÃ§larÄ± kaydet
    results_df.to_csv('results/metrics/model_comparison.csv', index=False)
    
    print("âœ… ÃœÃ‡ÃœNCÃœ ADIM TAMAMLANDI!")
    print("ğŸ”œ Sonraki adÄ±m: Hiperparametre optimizasyonu")

if __name__ == "__main__":
    main()